{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from typing import List,Optional\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_TOKEN = os.getenv('COHERE_TOKEN')\n",
    "MISTRAL_TOKEN = os.getenv('MISTRAL_TOKEN')\n",
    "OPENAI_TOKEN = os.getenv('OPENAI_TOKEN')\n",
    "os.environ['PINECONE_API_KEY'] = os.getenv('PINECONE')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredMarkdownLoader('processed_data/j.celrep.2013.07.030.md')\n",
    "loaded_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4096, chunk_overlap=128)\n",
    "docs = text_splitter.split_documents(loaded_documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'intfloat/multilingual-e5-large'\n",
    "#model_name = 'BAAI/bge-small-en-v1.5'\n",
    "model_name = 'BAAI/bge-m3'\n",
    "#model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'mps'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_docs = FAISS.from_documents(docs,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "retriever = vectorstore_from_docs.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"What animals are used in this study?\n",
    "         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = CohereRerank(model='rerank-english-v3.0',\n",
    "                          cohere_api_key=COHERE_TOKEN)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(model_name=\"mistral-large-latest\",temperature=0,api_key=MISTRAL_TOKEN)\n",
    "#llm = ChatOpenAI(\n",
    "#    model_name=\"gpt-4o-mini\",  \n",
    "#    openai_api_key=OPENAI_TOKEN, \n",
    "#    temperature=0.1 \n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal(BaseModel):\n",
    "    species: str = Field(description=\"Species of the animal\")\n",
    "    strain: str = Field(description=\"Strain of the animal\")\n",
    "    group: str = Field(description=\"Control or experiment group\")\n",
    "    gender: str = Field(description=\"Sex of the animal\")\n",
    "    n_treatment: Optional[int] = Field(description='Number of animals in this group')\n",
    "    n_control: Optional[int] = Field(description='Number of animals in control for this group')\n",
    "\n",
    "class AnimalList(BaseModel):\n",
    "    animals: list[Animal]\n",
    "parser = PydanticOutputParser(pydantic_object=AnimalList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant. Use the following information to answer the question very shortly\n",
    "Divide animals in groups ONLY from experimental groups (exclude any control or wildtype groups that are needed only for comparison with experimental groups) and describe each group\n",
    "Give an aswer in proper JSON format using double quotes around keys and values format: \n",
    "For example: {{\"animals\":[{{\"species\":\"animal_species1\",\n",
    "         \"strain\":\"animal_strain1\",\n",
    "         \"group\":\"experiment1\",# Name of the group for example Rapa_male, KO ABC gene and e.t.c\n",
    "         \"gender\":\"animal_sex1\",\n",
    "         \"n_treatment\":25,##Number of animals in this specific group\n",
    "         \"n_control\":40 #Number of animals in control relative to this group if no information - write null\n",
    "         }},\n",
    "         {{\"species\":\"animal_species2\",\n",
    "         \"strain\":\"animal_strain2\",\n",
    "         \"group\":\"experiment2\",# Name of the group for example Rapa_male, KO ABC gene and e.t.c\n",
    "         \"sex\":\"animal_sex2\",\n",
    "         \"n_treatment\":25,##Number of animals in this specific group\n",
    "         \"n_control\":40 ##Number of animals in control relative to this group if no information - write null\n",
    "         }}]}}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance, note the use of both 'context' and 'query'\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\",\"context\"],\n",
    "                        partial_variables={\"format_instructions\": parser.model_json_schema()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=compression_retriever,\n",
    "                                 chain_type_kwargs={\n",
    "                                     \"prompt\": prompt,\n",
    "                                     \"document_variable_name\": \"context\"\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer  = parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDetails(BaseModel):\n",
    "    treatment: str = Field(description=\"What type of treatment or intervention are used?\")\n",
    "    way_of_administration: str = Field(description=\"What way of administation are used?\")\n",
    "    age_at_start: int = Field(description=\"Age of the start of treamtment\")\n",
    "    duration_unit: str = Field(description=\"In which units age of the start was Month/Week/Day and e.t.c\")\n",
    "    dosage: str = Field(description=\"Dosage of administration\")\n",
    "class AnimalDetailsList(BaseModel):\n",
    "    animal_details: List[AnimalDetails]\n",
    "parser2 = PydanticOutputParser(pydantic_object=AnimalDetailsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_descriptions = [\n",
    "    f\"{animal.gender} {animal.species} {animal.group} {animal.strain}\" \n",
    "    for animal in answer.animals\n",
    "]\n",
    "all_animals_description = \", \".join(animal_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = \"\"\"\n",
    "You are an assistant. Use the following information to answer the question very shortly\n",
    "Describe what intervention is used for each groups of animals\n",
    "Give an answer in proper JSON format using double quotes around keys and values. \n",
    "For example: \n",
    "{{\n",
    "  \"animal_details\": [\n",
    "    {{\n",
    "      \"treatment\": \"treatment1\", # short name of the treatment or control\n",
    "      \"way_of_administration\": \"way_of_administration1\",# Food, Intravenous, Water, Intraperitoneal, Genomic and e.t.c\n",
    "      \"age_at_start\": 2,#write only value for example 2 (second month of the life)\n",
    "      \"duration_unit\": \"Months\"# Year, Month, Week, Day and e.t.c if age_at_start equal to 0 then write here Days\n",
    "      \"dosage\": \"dosage1\"#only doage values\n",
    "    }},\n",
    "    {{\n",
    "      \"treatment\": \"treatment2\",#short name of the treatment or control\n",
    "      \"way_of_administration\": \"way_of_administration2\",# Food, Intravenous, Water, Intraperitoneal,Genomic and e.t.c\n",
    "      \"age_at_start\": 0,#write only value for example 2 (second month of the life)\n",
    "      \"duration_unit\": \"Days\"# Year, Month, Week, Day and e.t.c if age_at_start equal to 0 then write here Days\n",
    "      \"dosage\": \"dosage2\"#only doage values\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance, note the use of both 'context' and 'query'\n",
    "prompt2 = PromptTemplate(template=prompt_template, input_variables=[\"query\",\"context\"],\n",
    "                        partial_variables={\"format_instructions\": parser2.model_json_schema()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = f\"\"\"\n",
    "What intervention is used for each groups of animals: {all_animals_description}?\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=prompt_template2,\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser2.model_json_schema()},\n",
    ")\n",
    "\n",
    "qa2 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt2, \"document_variable_name\": \"context\"},\n",
    ")\n",
    "result2 = qa2.run(query2)\n",
    "answer2 = parser2.invoke(result2)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalResults(BaseModel):\n",
    "    median_treatment: Optional[float] = Field(description=\"Median treatment duration in units\")\n",
    "    max_treatment: Optional[float] = Field(description=\"Max treatment duration in units\")\n",
    "    treatment_units: str = Field(description=\"In what units measured lifespan\")\n",
    "    p_value: Optional[str] = Field(description=\"p-value for statistical analysis\")\n",
    "class AnimalResultsList(BaseModel):\n",
    "    animal_results: List[AnimalResults]\n",
    "parser3 = PydanticOutputParser(pydantic_object=AnimalResultsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template3 = \"\"\"\n",
    "Write life-span results for each group of animals. \n",
    "Give an answer in proper JSON format using double quotes around keys and values. \n",
    "For example: \n",
    "{{\n",
    "  \"animal_results\": [\n",
    "    {{\n",
    "      \"median_treatment\": 10.5, # median treatment lifespan of the group (only value)\n",
    "      \"max_treatment\": 15.3,# max treatment lifespan of the group (only value)\n",
    "      \"treatment_units\":\"treatment_units1\" # In what units measured lifespan Month, Age, Week\n",
    "      \"p_value\":0.01 #p-value of statistical test if exist (only value)\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = f\"\"\"\n",
    "Life-span results for each group of animals: {all_animals_description}\n",
    "\"\"\"\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template=prompt_template3,\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser3.model_json_schema()},\n",
    ")\n",
    "\n",
    "qa3 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt3, \"document_variable_name\": \"context\"},\n",
    ")\n",
    "result3 = qa3.run(query3)\n",
    "answer3 = parser3.invoke(result3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
